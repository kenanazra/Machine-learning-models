{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "89a2f1a1-aa32-456e-a7f1-c8d3d8a33263",
   "metadata": {},
   "source": [
    "# Machine learning models\n",
    "Dieses Projekt bietet eine vielfältige Auswahl an Klassifikationsmodellen für maschinelles Lernen. Benutzer können Modelle manuell auswählen oder sich basierend auf ihren spezifischen Anforderungen und Analysebedürfnissen für eine automatische Auswahl entscheiden."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64e8d824-8d7e-4627-958b-932d2f191d15",
   "metadata": {},
   "source": [
    "### Bibliotheken importieren"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b6ddffb8-5a1b-4abc-8f72-b6773f8044db",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HP\\anaconda3\\Lib\\site-packages\\tpot\\builtins\\__init__.py:36: UserWarning: Warning: optional dependency `torch` is not available. - skipping import of NN models.\n",
      "  warnings.warn(\"Warning: optional dependency `torch` is not available. - skipping import of NN models.\")\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.datasets import load_breast_cancer\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.impute import KNNImputer\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.model_selection import LeaveOneOut\n",
    "from sklearn.model_selection import LeavePOut\n",
    "from sklearn.model_selection import ShuffleSplit\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "from tpot import TPOTClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestRegressor, StackingClassifier, BaggingClassifier, GradientBoostingClassifier\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix, roc_curve, auc, mean_squared_error, mean_absolute_error, r2_score, root_mean_squared_error\n",
    "from scipy import stats as st\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "823c4fc5-e6b6-4546-b652-9c4c779e57c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install --upgrade tpot"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f418846-7a1c-4ef7-a141-07ce2e49c5f8",
   "metadata": {},
   "source": [
    "###  Daten laden und analysieren\n",
    "Hier wird der Datensatz analysiert und überprüft, ob fehlende Werte (z. B. NaN) oder doppelte Zeilen vorhanden sind"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d50b6462-30cc-46e1-be2a-1b280847effa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "''"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tkinter as tk\n",
    "from tkinter import filedialog, messagebox\n",
    "import pandas as pd\n",
    "\n",
    "def laden():\n",
    "    # Zeige eine Nachricht an\n",
    "    messagebox.showinfo(\"Dateiauswahl\", \"Bitte wählen Sie eine Datei aus.\")\n",
    "    \n",
    "    # Datei auswählen\n",
    "    filepath = filedialog.askopenfilename()\n",
    "    if not filepath:\n",
    "        print(\"Keine Datei ausgewählt.\")\n",
    "        return None\n",
    "    \n",
    "    # CSV-Datei lesen\n",
    "    df = pd.read_csv(filepath)\n",
    "    \n",
    "    # Hier kannst du deine Funktion aufrufen, z. B.:\n",
    "    data = Data_imputation(df)\n",
    "    print(\"Imputation abgeschlossen.\")\n",
    "    \n",
    "    return data\n",
    "\n",
    "# Hauptfenster initialisieren\n",
    "root = tk.Tk()\n",
    "root.withdraw()  # Das Hauptfenster ausblenden\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26b04940-969b-438f-8ff9-34aac27fdba0",
   "metadata": {},
   "source": [
    "### Analyse und Überprüfung des Datensatzes auf fehlende Werte und Dubletten"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "da935a6b-6930-4b87-9dcb-f77227f3ad61",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Data_imputation(data):\n",
    "    # Überprüfen, ob data DataFrame ist\n",
    "    if not isinstance(data, pd.DataFrame):\n",
    "        print('Die eingegebenen Daten sind kein DataFrame. Bitte konvertieren Sie die Daten zuerst in ein DataFrame.')\n",
    "        return None \n",
    "#\n",
    "    # Fragen, ob der Datensatz angezeigt werden soll\n",
    "    anzeigen = input('Möchten Sie die Daten anzeigen? (ja/nein): ').strip().lower()\n",
    "    if anzeigen == 'ja':\n",
    "        print('\\nHier ist der Datensatz als DataFrame:')\n",
    "        from IPython.display import display  # Optional für bessere Darstellung in Jupyter Notebook\n",
    "        display(data)\n",
    "    elif anzeigen == 'nein':\n",
    "        print('\\nDie Daten werden nicht angezeigt.')\n",
    "    else:\n",
    "        print('Ungültige Eingabe. Es wird davon ausgegangen, dass die Daten nicht angezeigt werden.')\n",
    "    \n",
    "    # Fragen, ob der Analyseprozess fortgesetzt werden soll\n",
    "    weiter_analyse = input('Möchten Sie mit der Analyse fortfahren? (ja/nein): ').strip().lower()\n",
    "    if weiter_analyse == 'nein':\n",
    "        print('Der Prozess wurde beendet.')\n",
    "        return None\n",
    "    elif weiter_analyse != 'ja':\n",
    "        print('Ungültige Eingabe. Der Prozess wird beendet.')\n",
    "        return None#    \n",
    "    # Allgemeine Informationen zum Datensatz\n",
    "    print('\\n1. Allgemeine Informationen zum Datensatz:')\n",
    "    print(data.info())\n",
    "\n",
    "    # Überprüfung auf fehlende Werte\n",
    "    print('\\n2. Überprüfung auf fehlende Werte:')\n",
    "    missing_values = data.isnull().sum().sum()\n",
    "    if missing_values > 0:\n",
    "        print(data.isnull().sum()) \n",
    "    else:\n",
    "        print('Es gibt keine fehlenden Werte.')\n",
    "\n",
    "    # Überprüfung auf doppelte Zeilen\n",
    "    print('\\n3. Überprüfung des Duplikates:')\n",
    "    duplicated_rows = data.duplicated().sum()\n",
    "    if duplicated_rows > 0:\n",
    "        print(f'Es gibt {duplicated_rows} doppelte Zeilen.')\n",
    "        drop_duplicates = input('Möchten Sie die doppelten Zeilen entfernen? (ja/nein): ').strip().lower()\n",
    "        if drop_duplicates == 'ja':\n",
    "            data = data.drop_duplicates()\n",
    "            print('Die doppelten Zeilen wurden entfernt.')\n",
    "    else:\n",
    "        print('Es gibt keine doppelten Zeilen.')\n",
    "\n",
    "    # wenn keine fehlenden Werte oder Duplikat vorhanden sind\n",
    "    if missing_values == 0 and duplicated_rows == 0:\n",
    "        print('\\nEs sind weder fehlende Werte noch doppelte Zeilen vorhanden. Es ist keine Imputation erforderlich.')\n",
    "        return data\n",
    "    else:\n",
    "        print('\\nFehlende Werte sind vorhanden und können durch die folgenden Methoden vervollständigt werden. ')\n",
    "       \n",
    "    # Imputationsmethoden\n",
    "    while True:\n",
    "        print('\\nWähle eine Methode zur Imputation fehlender Werte:')\n",
    "        print('1: Mean/Median/Mode Imputation (numerische Spalten)')\n",
    "        print('2: Predictive Imputation (KNN, numerische Spalten)')\n",
    "        print('3: Last Observation Carried Forward (LOCF, alle Spalten)')\n",
    "        print('4: Mode Imputation (nicht-numerische Spalten)')\n",
    "        \n",
    "        method = input('Gib die Nummer der gewünschten Methode ein: ')\n",
    "        \n",
    "        if method not in ['1', '2', '3', '4']:\n",
    "            print('Ungültige Eingabe. Bitte wähle eine gültige Methode aus.')\n",
    "            continue\n",
    "\n",
    "        # Implementierung der gewählten Imputationsmethode\n",
    "        else:\n",
    "            if method == '1':\n",
    "                strategy = input('Wählen Sie Methode (mean/median/most_frequent): ').strip().lower()\n",
    "                numeric_cols = data.select_dtypes(include=['float64', 'int64']).columns\n",
    "                imputer = SimpleImputer(missing_values=np.nan, strategy=strategy)\n",
    "                data[numeric_cols] = imputer.fit_transform(data[numeric_cols])\n",
    "                print('\\nDatensatz nach Mean/Median/Mode Imputation:')\n",
    "                print(data)\n",
    "                print(data.isnull().sum()) \n",
    "\n",
    "            elif method == '2':\n",
    "                n_neighbors = int(input('Gib die Anzahl der Nachbarn für KNN ein: '))\n",
    "                numeric_cols = data.select_dtypes(include=['float64', 'int64']).columns\n",
    "                imputer = KNNImputer(n_neighbors=n_neighbors)\n",
    "                data[numeric_cols] = imputer.fit_transform(data[numeric_cols])\n",
    "                print('\\nDatensatz nach Predictive Imputation (KNN):')\n",
    "                print(data)\n",
    "                print(data.isnull().sum())\n",
    "\n",
    "            elif method == '3':\n",
    "                data = data.fillna(method='ffill')  # LOCF\n",
    "                print('\\nDatensatz nach Last Observation Carried Forward (LOCF):')\n",
    "                print(data)\n",
    "                print(data.isnull().sum())\n",
    "\n",
    "            elif method == '4':\n",
    "                non_numeric_cols = data.select_dtypes(include=['object', 'category']).columns\n",
    "                imputer = SimpleImputer(strategy='most_frequent')\n",
    "                data[non_numeric_cols] = imputer.fit_transform(data[non_numeric_cols])\n",
    "                print('\\nDatensatz nach Mode Imputation (für nicht-numerische Spalten):')\n",
    "                print(data)\n",
    "                print(data.isnull().sum())\n",
    "\n",
    "        # Frage, ob eine weitere Methode verwendet werden soll\n",
    "        weitere_methode = input('Möchten Sie eine weitere Methode anwenden? (ja/nein): ').strip().lower()\n",
    "        if weitere_methode == 'nein':\n",
    "            print('Imputationsprozess abgeschlossen.')\n",
    "            break\n",
    "\n",
    "    # Wiederholte Abfrage, ob Spalten entfernt werden sollen\n",
    "    while True:\n",
    "        col_drop = input('Möchten Sie Spalten entfernen? (ja/nein): ').strip().lower()\n",
    "        if col_drop == 'ja':\n",
    "            while True:\n",
    "                cols_Name = input('Geben Sie die Namen der Spalten ein (z.B Name, alter ....): ').strip().split(',')\n",
    "                cols_Name = [col.strip() for col in cols_Name]  # Leerzeichen entfernen\n",
    "                invalid_cols = [col for col in cols_Name if col not in data.columns]\n",
    "            \n",
    "                if invalid_cols:\n",
    "                    print(f\"Die folgenden Spalten existieren nicht im Datensatz: {', '.join(invalid_cols)}\")\n",
    "                    print(\"Bitte geben Sie gültige Spaltennamen ein.\")\n",
    "                else:\n",
    "                    data = data.drop(columns=cols_Name)  # Entfernt gültige Spalten\n",
    "                    print('Die ausgewählten Spalten wurden entfernt.')\n",
    "                    print(data.info())\n",
    "                    break\n",
    "        elif col_drop == 'nein':\n",
    "            print('Es werden keine weiteren Spalten entfernt.')\n",
    "            break\n",
    "    else:\n",
    "        print('Ungültige Eingabe. Bitte antworten Sie mit ja oder nein.')\n",
    "    return data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dea7264d-5e75-44a3-9b3e-525cbd4219ea",
   "metadata": {},
   "source": [
    "### Splitten der Daten in X (Inputs) und y (Output)\n",
    "Hier wird der Datensatz in X (Inputs) und y (Output) splitten"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "924a9990-72fe-4493-9cec-31741e997d9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_data(data):\n",
    "\n",
    "    while True:\n",
    "        output_cols = input('Geben Sie die Namen der Output-Spalten (y) ein: ')\n",
    "    \n",
    "        # Überprüfen, ob alle eingegebenen Output-Spalten im DataFrame existieren\n",
    "        \n",
    "        if output_cols not in data.columns:\n",
    "            print('Geben Sie bitte einenerneut eingeben')\n",
    "        else:\n",
    "            break\n",
    "\n",
    "    # Input-Spalten (alle Spalten außer den Output-Spalten)\n",
    "    input_cols = [col for col in data.columns if col not in output_cols]\n",
    "    \n",
    "    # Splitten der Daten in X (Inputs) und y (Outputs)\n",
    "    X = data[input_cols]\n",
    "    y = data[output_cols]\n",
    "    \n",
    "    print('\\nInputs (X):')\n",
    "    print(X.head())\n",
    "    print('\\nOutputs (y):')\n",
    "    print(y.head())\n",
    "\n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7098ef6-7e8c-4f56-9700-6203e6bf30a5",
   "metadata": {},
   "source": [
    "### Überprüfen des Datensatzes auf mögliche Fehler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "552181cb-c44d-47da-8ba1-c29f35b8a28c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#    Überprüft X und y auf mögliche Fehler, wie z.B. Strings in numerischen Spalten.\n",
    "#   Gibt problematische Spalten/Werte aus und gibt die bereinigten Daten zurück.\n",
    "\n",
    "def check_data_for_errors(X, y):\n",
    "\n",
    "    print('\\nÜberprüfung der Daten auf mögliche Fehler...\\n')\n",
    "\n",
    "    def check_columns(data, dataset_name):\n",
    "        '''\n",
    "        Hilfsfunktion zur Überprüfung der Spalten eines einzelnen Datensatzes.\n",
    "        '''\n",
    "        error_columns = []\n",
    "        print(f'\\nÜberprüfung von {dataset_name}...\\n')\n",
    "        for col in data.columns:\n",
    "            try:\n",
    "                # Teste, ob alle Werte in der Spalte in Floats umgewandelt werden können\n",
    "                data[col].astype(float)\n",
    "            except ValueError as e:\n",
    "                error_columns.append(col)\n",
    "                print(f'Fehler in {dataset_name}, Spalte {col}: {e}')\n",
    "        return error_columns\n",
    "\n",
    "    # Problematische Spalten finden\n",
    "    problem_X = check_columns(X, 'X')\n",
    "    problem_y = []\n",
    "\n",
    "    # Überprüfung für y\n",
    "    try:\n",
    "        y.astype(float)\n",
    "    except ValueError as e:\n",
    "        problem_y.append('y')\n",
    "        print(f'Fehler in y: {e}')\n",
    "\n",
    "    # Zusammenfassung der problematischen Spalten/Werte\n",
    "    if problem_X or problem_y:\n",
    "        print('\\nZusammenfassung der problematischen Spalten/Werte:')\n",
    "        if problem_X:\n",
    "            print(f'X: {', '.join(problem_X)}')\n",
    "        if problem_y:\n",
    "            print('y enthält problematische Werte.')\n",
    "        \n",
    "        # Benutzeroptionen\n",
    "        action = input('Möchten Sie die problematischen Spalten löschen oder bearbeiten? (löschen/bearbeiten): ').strip().lower()\n",
    "        while action not in ['löschen', 'bearbeiten', '']:\n",
    "            action = input('Ungültige Eingabe. Bitte wählen Sie löschen oder bearbeiten: ').strip().lower()\n",
    "        \n",
    "        if action == 'löschen':\n",
    "            X = X.drop(columns=problem_X)\n",
    "            print('Die problematischen Spalten wurden aus X entfernt.')\n",
    "        elif action == 'bearbeiten':\n",
    "            print('Bitte bearbeiten Sie die problematischen Spalten oder Werte manuell.')\n",
    "        else:\n",
    "            print('Keine Aktion wurde ausgeführt.')\n",
    "    else:\n",
    "        print('Es wurden keine problematischen Spalten oder Werte gefunden. Alle Daten scheinen in Ordnung zu sein.')\n",
    "    \n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ba1edee-75b9-4762-9047-362dfc1ff704",
   "metadata": {},
   "source": [
    "### feature Scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "844b9c3e-4387-4f08-abef-72d8b8c06396",
   "metadata": {},
   "outputs": [],
   "source": [
    "def feature_scaling(X_train, X_test):\n",
    "    Feature_Scaling = input('\\nMöchten Sie ein Feature-Scaling durchführen (Ja/Nein): ')\n",
    "    if Feature_Scaling.lower() == 'ja':\n",
    "        Feature_Scaling_Methode = input('\\nWelche Methode möchten Sie durchführen (Standardization/Normalization)?: ')\n",
    "        while Feature_Scaling_Methode.lower() not in ['standardization', 'normalization']:\n",
    "            print('Wählen Sie eine Methode von der Liste aus.')\n",
    "            Feature_Scaling_Methode = input('\\nWelche Methode möchten Sie durchführen (Standardization/Normalization)?: ')\n",
    "                \n",
    "        if Feature_Scaling_Methode.lower() == 'standardization':\n",
    "            scaler = StandardScaler()\n",
    "            X_train = scaler.fit_transform(X_train)\n",
    "            X_test = scaler.transform(X_test)\n",
    "        elif Feature_Scaling_Methode.lower() == 'normalization':\n",
    "            min_max_scaler = MinMaxScaler()\n",
    "            X_train = min_max_scaler.fit_transform(X_train)\n",
    "            X_test = min_max_scaler.transform(X_test)\n",
    "    \n",
    "    return X_train, X_test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1237b153-4e6d-4a87-b437-4cf458c922ad",
   "metadata": {},
   "source": [
    "## Model-Aufbau"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a7c5e81-8592-48d4-80c0-466ed928c58a",
   "metadata": {},
   "source": [
    "### automatisches Auswahl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "bae42dd8-6fef-4ac2-998d-e21427528755",
   "metadata": {},
   "outputs": [],
   "source": [
    "# automatisches Auswahl\n",
    "def model_TPOTClassifier(X_train,y_train):\n",
    "    tpot = TPOTClassifier(generations=8, population_size=20, verbosity=2)\n",
    "    tpot.fit(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b18cf30-1c6b-45d1-ad15-d490c473f05c",
   "metadata": {},
   "source": [
    "### LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "de95e69d-862d-48ce-b980-89bde2a84e9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# LogisticRegression\n",
    "def model_logistic_regression(X_train, y_train, X_test, y_test):\n",
    "    model = LogisticRegression()\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "\n",
    "    # Ergebnisse auswerten\n",
    "    print('\\nKlassifikationsbericht:')\n",
    "    print(classification_report(y_test, y_pred))\n",
    "\n",
    "    print('\\nKonfusionsmatrix:')\n",
    "    print(confusion_matrix(y_test, y_pred))\n",
    "\n",
    "    return model  # <-- Hier geben wir das Modell zurück!\n",
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b74b6ddf-3384-4796-b198-902c12a8f904",
   "metadata": {},
   "source": [
    "### Support Vector Machines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "669baa97-3124-4afc-b136-1f80fdda777c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Support Vector Machines\n",
    "def model_svm(X_train, y_train, X_test, y_test):\n",
    "    param_grid = {'C': [0.1, 1, 10],\n",
    "                  'gamma': ['scale', 'auto'],\n",
    "                  'kernel': ['linear', 'rbf']}\n",
    "    \n",
    "    grid = GridSearchCV(SVC(), param_grid, refit=True, verbose=0)\n",
    "    grid.fit(X_train, y_train)\n",
    "    \n",
    "    best_model = grid.best_estimator_\n",
    "    y_pred = best_model.predict(X_test)\n",
    "    \n",
    "    # Ergebnisse auswerten\n",
    "    print('\\nKlassifikationsbericht:')\n",
    "    print(classification_report(y_test, y_pred))\n",
    "    print('\\nKonfusionsmatrix:')\n",
    "    print(confusion_matrix(y_test, y_pred))\n",
    "    return best_model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15a2bc35-d59a-4957-a2bb-a112bf6cb9b6",
   "metadata": {},
   "source": [
    "### K-Nearest Neighbors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "f353fd11-cbb2-4616-8313-13742da0638e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# K-Nearest Neighbors\n",
    "def model_knn(X_train, y_train, X_test, y_test):\n",
    "    param_grid = {'n_neighbors': np.arange(1, 31),\n",
    "                  'weights': ['uniform', 'distance']}\n",
    "    \n",
    "    grid = GridSearchCV(KNeighborsClassifier(), param_grid, cv=5, verbose=0)\n",
    "    grid.fit(X_train, y_train)\n",
    "    \n",
    "    best_knn = grid.best_estimator_\n",
    "    y_pred   = best_knn.predict(X_test)\n",
    "    \n",
    "    # Ergebnisse auswerten\n",
    "    print('\\nKlassifikationsbericht:')\n",
    "    print(classification_report(y_test, y_pred))\n",
    "    print('\\nKonfusionsmatrix:')\n",
    "    print(confusion_matrix(y_test, y_pred))\n",
    "    return best_knn"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "177f91aa-4ef0-4028-8d3a-f714bc300c9c",
   "metadata": {},
   "source": [
    "### Naive Bayes ( GaussianNB)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "1643f215-dc69-4ba3-9a55-6f8b0964ceb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Naive Bayes ( GaussianNB)\n",
    "def model_gaussian_nb(X_train, y_train, X_test, y_test):\n",
    "    model = GaussianNB()\n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "    y_pred = model.predict(X_test)\n",
    "    \n",
    "    # Ergebnisse auswerten\n",
    "    print('\\nKlassifikationsbericht:')\n",
    "    print(classification_report(y_test, y_pred))\n",
    "    print('\\nKonfusionsmatrix:')\n",
    "    print(confusion_matrix(y_test, y_pred))\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccec6ca6-21b9-496b-954d-72bd03c9da2f",
   "metadata": {},
   "source": [
    "### Decision Trees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "d75ef971-e380-4c92-96a5-8ee1e56c39be",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Decision Trees\n",
    "def model_decision_tree(X_train, y_train, X_test, y_test):\n",
    "    param_grid = {'max_depth': [3, 4, 5, 6, 7, None],\n",
    "                  'min_samples_split': [2, 5, 10],\n",
    "                  'min_samples_leaf': [1, 2, 4],\n",
    "                  'criterion': ['gini', 'entropy']}\n",
    "    \n",
    "    grid_search = GridSearchCV(estimator=DecisionTreeClassifier(), param_grid=param_grid, cv=5, n_jobs=-1, verbose=2)\n",
    "    grid_search.fit(X_train, y_train)\n",
    "    \n",
    "    #print('Best parameters found: ', grid_search.best_params_)\n",
    "    #print('Best score: ', grid_search.best_score_)\n",
    "\n",
    "    y_pred   = grid_search.best_estimator_.predict(X_test)\n",
    "    \n",
    "    # Ergebnisse auswerten\n",
    "    print('\\nKlassifikationsbericht:')\n",
    "    print(classification_report(y_test, y_pred))\n",
    "    print('\\nKonfusionsmatrix:')\n",
    "    print(confusion_matrix(y_test, y_pred))    \n",
    "    return grid_search.best_estimator_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "caa7e4eb-3a97-4695-8249-6850439f4eec",
   "metadata": {},
   "source": [
    "### Random forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "29d400d0-7961-4620-aeee-15be3af9a8f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Random forest\n",
    "def model_Random_forest(X_train, y_train, X_test, y_test):\n",
    "    param_grid = {\n",
    "    'n_estimators': [10,100, 200, 300],\n",
    "    #'max_depth': [None, 10, 20, 30],\n",
    "    'min_samples_split': [2, 5, 10],\n",
    "    #'min_samples_leaf': [1, 2, 4],\n",
    "    #'bootstrap': [True, False]\n",
    "    }\n",
    "\n",
    "    # Erstelle das GridSearchCV-Objekt\n",
    "    grid_search = GridSearchCV(estimator=RandomForestRegressor(), param_grid=param_grid, cv=5, scoring='neg_mean_squared_error')\n",
    "\n",
    "    # Führe Grid Search aus\n",
    "    grid_search.fit(X_train, y_train)\n",
    "\n",
    "    # Beste Parameter\n",
    "    best_params = grid_search.best_params_\n",
    "    best_model = grid_search.best_estimator_\n",
    "    y_pred   = best_model.predict(X_test)\n",
    "\n",
    "    # Ergebnisse auswerten\n",
    "    mse      = mean_squared_error(y_test,y_pred)\n",
    "    mae      = mean_absolute_error(y_test,y_pred)\n",
    "    score_r2 = r2_score(y_test,y_pred)\n",
    "    rmse     = root_mean_squared_error(y_test,y_pred)\n",
    "\n",
    "    #print(mse)\n",
    "    #print(mae)\n",
    "    print(f'score_r2 = {score_r2}')\n",
    "    #print(rmse)\n",
    "    return best_model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0aba375a-7507-4cbd-ae84-5f91625ed39c",
   "metadata": {},
   "source": [
    "### Max Voting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "3c2f8353-7959-44d9-b752-6ee6a4a7c469",
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_Max_Voting(model_switch, X_train, y_train, X_test, y_test):\n",
    "    print('Max Voting wurde ausgewählt.')\n",
    "    \n",
    "    # Benutzer kann die Modelle auswählen\n",
    "    print('\\nVerfügbare Modelle:')\n",
    "    for key, model_function in model_switch.items():\n",
    "        if key not in ['6', '7', '8', '9', '10']:  \n",
    "            print(f'{key}: {model_function.__name__}')\n",
    "    \n",
    "    selected_models = input('\\nBitte wählen Sie die Modelle für Max Voting (z.B. 1,2,3): ').split(',')\n",
    "    selected_models = [m.strip() for m in selected_models]  # Entfernen von Leerzeichen\n",
    "\n",
    "    # Überprüfen der Gültigkeit der Eingaben\n",
    "    valid_models = []\n",
    "    for model_key in selected_models:\n",
    "        if model_key in model_switch and model_key != '7' :\n",
    "            valid_models.append(model_key)\n",
    "        else:\n",
    "            print(f'Modell {model_key} ist ungültig und wird übersprungen.')\n",
    "\n",
    "    if not valid_models:\n",
    "        print('Keine gültigen Modelle ausgewählt. Abbruch.')\n",
    "        return None\n",
    "\n",
    "    # Training der ausgewählten Modelle und Sammeln der Vorhersagen\n",
    "    predictions = []\n",
    "    for model_key in valid_models:\n",
    "        model_function = model_switch[model_key]  # Funktion aus model_switch abrufen\n",
    "        print(f'Training Modell {model_key} ({model_function.__name__})...')\n",
    "        trained_model = model_function(X_train, y_train, X_test, y_test)  # Modell trainieren\n",
    "        y_pred = trained_model.predict(X_test)\n",
    "        predictions.append(y_pred)\n",
    "    \n",
    "    # Umwandlung der Vorhersagen in ein NumPy-Array\n",
    "    predictions = np.array(predictions)\n",
    "\n",
    "    # Berechnung der finalen Vorhersage mit mode()\n",
    "    from scipy.stats import mode\n",
    "    final_pred, _ = mode(predictions, axis=0)\n",
    "\n",
    "    # Sicherstellen, dass final_pred die richtige Form hat\n",
    "    final_pred = final_pred.ravel()\n",
    "\n",
    "    print('Final Prediction:')\n",
    "    print(final_pred)\n",
    "\n",
    "    print('\\nKlassifikationsbericht:')\n",
    "    print(classification_report(y_test, final_pred))\n",
    "    print('\\nKonfusionsmatrix:')\n",
    "    print(confusion_matrix(y_test, final_pred))\n",
    "    print('\\nMax Voting: Max Voting ist eine Voting-Methode, bei der mehrere Modelle trainiert werden und die Klasse mit den meisten Stimmen als endgültige Vorhersage ausgewählt wird. Es wird häufig in Klassifikationsproblemen verwendet.')\n",
    "    return final_pred\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15b2fd14-cb95-4d14-8a19-2e73ad326930",
   "metadata": {},
   "source": [
    "### Stacking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "0f1fa417-283d-420d-97f0-43c3758f029b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Funktion für Stacking\n",
    "def model_Stacking(model_switch, X_train, y_train, X_test, y_test):\n",
    "    print('Stacking wurde ausgewählt.')\n",
    "    \n",
    "    # Benutzer kann die Modelle auswählen\n",
    "    print('\\nVerfügbare Modelle:')\n",
    "    for key in model_switch:\n",
    "        if key != '6' and key != '7' and key != '8' and key != '9' and key != '10': \n",
    "            print(f'{key}: {model_switch[key].__name__}')\n",
    "    \n",
    "    selected_models = input('\\nBitte wählen Sie die Modelle für Stacking (z.B. 1,2,3): ').split(',')\n",
    "    selected_models = [m.strip() for m in selected_models]  # Entfernen von Leerzeichen\n",
    "    print(selected_models)\n",
    "    # Überprüfen der Gültigkeit der Eingaben\n",
    "    valid_models = []\n",
    "    for model_key in selected_models:\n",
    "        if model_key in model_switch and model_key != '8':\n",
    "            valid_models.append(model_key)\n",
    "        else:\n",
    "            print(f'Modell {model_key} ist ungültig und wird übersprungen.')\n",
    "\n",
    "    if not valid_models:\n",
    "        print('Keine gültigen Modelle ausgewählt. Abbruch.')\n",
    "        return None\n",
    "\n",
    "    # Training der ausgewählten Modelle und Sammeln der Modelle für Stacking\n",
    "    base_models = []\n",
    "    for model_key in valid_models:\n",
    "        model_function = model_switch[model_key]  # Funktion aus model_switch abrufen\n",
    "        print(f'Training Modell {model_key} ({model_function.__name__})...')\n",
    "        trained_model = model_function(X_train, y_train, X_test, y_test)  # Modell trainieren\n",
    "        base_models.append((f'model_{model_key}', trained_model))\n",
    "    print(base_models)\n",
    "    # Definition des Meta-Modells\n",
    "    meta_model = LogisticRegression()\n",
    "\n",
    "    # Erstellen des Stacking Classifiers\n",
    "    stacking_clf = StackingClassifier(estimators=base_models, final_estimator=meta_model)\n",
    "\n",
    "    # Training des Stacking Classifiers\n",
    "    stacking_clf.fit(X_train, y_train)\n",
    "\n",
    "    # Vorhersage mit dem Stacking Classifier\n",
    "    y_pred = stacking_clf.predict(X_test)\n",
    "\n",
    "    # Evaluierung des Modells\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    print(f'Stacking Classifier Accuracy: {accuracy}')\n",
    "    print('\\nKlassifikationsbericht:')\n",
    "    print(classification_report(y_test, y_pred))\n",
    "    print('\\nKonfusionsmatrix:')\n",
    "    print(confusion_matrix(y_test, y_pred))\n",
    "    print('\\nStacking: Stacking kombiniert die Ergebnisse mehrerer Modelle, indem ihre Vorhersagen als Eingabe für ein Metamodell genutzt werden. Das Ziel ist es, die Stärken der einzelnen Modelle zu vereinen und eine bessere Leistung zu erzielen.')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ade589a5-0631-4e8c-9b8c-80f0c2d40faf",
   "metadata": {},
   "source": [
    "###  Bagging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "3ff5ecec-eb41-4020-a8ed-3b60d1a21061",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Bagging: Bagging steht für Bootstrap Aggregating und verwendet mehrere unabhängige Modelle, die auf zufälligen Datenstichproben trainiert werden. Die Vorhersagen der Modelle werden aggregiert, um die Varianz zu reduzieren und die Gesamtleistung zu verbessern. Ein bekanntes Beispiel ist der Random Forest.\n"
     ]
    }
   ],
   "source": [
    "# Funktion Bagging\n",
    "def model_Bagging(model_switch, X_train, y_train, X_test, y_test):\n",
    "\n",
    "    print('Bagging wurde ausgewählt.')\n",
    "    \n",
    "    # Benutzer kann die Modelle auswählen\n",
    "    print('\\nVerfügbare Modelle:')\n",
    "    for key in model_switch:\n",
    "        if key != '6' and key != '7' and key != '8' and key != '9' and key != '10' : \n",
    "            print(f'{key}: {model_switch[key].__name__}')\n",
    "    \n",
    "    selected_models = input('\\nBitte wählen Sie ein Modell für Bagging : ').split(',')\n",
    "    selected_models = [m.strip() for m in selected_models]  # Entfernen von Leerzeichen\n",
    "    print(selected_models)\n",
    "    \n",
    "    # Überprüfen der Gültigkeit der Eingaben\n",
    "    valid_models = []\n",
    "    for model_key in selected_models:\n",
    "        if model_key in model_switch and model_key != '9':\n",
    "            valid_models.append(model_key)\n",
    "        else:\n",
    "            print(f'Modell {model_key} ist ungültig und wird übersprungen.')\n",
    "\n",
    "    if not valid_models:\n",
    "        print('Keine gültigen Modelle ausgewählt. Abbruch.')\n",
    "\n",
    "    # Training der ausgewählten Modelle und Sammeln der Modelle für Bagging\n",
    "    model_function = model_switch[model_key]  \n",
    "    print(f'Training Modell {model_key} ({model_function.__name__})...')\n",
    "    trained_model = model_function(X_train, y_train, X_test, y_test) \n",
    "    #print(trained_model)\n",
    "    # Hyperparameter-Raster für BaggingClassifier\n",
    "    bc_params = {\n",
    "        'n_estimators': [10, 20, 30],\n",
    "        'max_samples': [0.5, 0.7, 1.0],\n",
    "        'max_features': [0.5, 0.7, 1.0]\n",
    "    }\n",
    "    \n",
    "    # Grid Search für BaggingClassifier\n",
    "    bagging_clf = BaggingClassifier(trained_model)\n",
    "    bc_gs = GridSearchCV(bagging_clf, bc_params, cv=5, verbose=1)\n",
    "\n",
    "    bc_gs.fit(X_train, y_train)\n",
    "    y_pred = bc_gs.predict(X_test)\n",
    "\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    print(f'BaggingClassifier Accuracy: {accuracy}')\n",
    "    print('\\nKlassifikationsbericht:')\n",
    "    print(classification_report(y_test, y_pred))\n",
    "    print('\\nKonfusionsmatrix:')\n",
    "    print(confusion_matrix(y_test, y_pred))\n",
    "print('\\nBagging: Bagging steht für Bootstrap Aggregating und verwendet mehrere unabhängige Modelle, die auf zufälligen Datenstichproben trainiert werden. Die Vorhersagen der Modelle werden aggregiert, um die Varianz zu reduzieren und die Gesamtleistung zu verbessern. Ein bekanntes Beispiel ist der Random Forest.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59dc0f8e-6ed2-4607-bc0b-64afd89c5122",
   "metadata": {},
   "source": [
    "### Boosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "e5f9557e-a7ca-4b52-a7cd-e2bfd33dd6a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Funktion Boosting\n",
    "def model_Boosting(model_switch, X_train, y_train, X_test, y_test):\n",
    "    print('Boosting wurde ausgewählt.')\n",
    "    # Hyperparameter-Raster für GradientBoostingClassifier\n",
    "    gbc_params = {\n",
    "        'n_estimators': [100, 200, 500],\n",
    "        'learning_rate': [0.01, 0.05, 0.1],\n",
    "        'max_features': [None, 'sqrt', 'log2'],\n",
    "         'max_depth': [3, 5, 7],\n",
    "        #'min_samples_split': [2, 5, 10],\n",
    "        #'min_samples_leaf': [1, 2, 4]\n",
    "    }\n",
    "    \n",
    "    # Grid Search für GradientBoostingClassifier\n",
    "    gbc = GradientBoostingClassifier(random_state=100)\n",
    "    gbc_gs = GridSearchCV(gbc, gbc_params, cv=5, verbose=1, n_jobs=-1)\n",
    "\n",
    "    gbc_gs.fit(X_train, y_train)\n",
    "\n",
    "    y_pred = gbc_gs.predict(X_test)\n",
    "\n",
    "    # Modell evaluieren\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    print(f'GradientBoostingClassifier Accuracy: {accuracy}')\n",
    "    print('\\nKlassifikationsbericht:')\n",
    "    print(classification_report(y_test, y_pred))\n",
    "    print('\\nKonfusionsmatrix:')\n",
    "    print(confusion_matrix(y_test, y_pred))\n",
    "    print('\\nBoosting: Boosting ist eine iterative Methode, bei der schwache Modelle (z. B. Entscheidungsbäume mit geringer Tiefe) nacheinander trainiert werden. Jedes neue Modell versucht, die Fehler des vorherigen Modells zu korrigieren. Am Ende werden die Ergebnisse der Modelle gewichtet kombiniert, um eine bessere Gesamtleistung zu erzielen. Bekannte Algorithmen: AdaBoost, Gradient Boosting.')\n",
    "    return gbc_gs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13b9ce5c-7468-4bbe-aeb7-ad15ae4b6b66",
   "metadata": {},
   "source": [
    "### validation_techniques"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "91050940-dc73-4001-b017-69ddaf7c4aca",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def validation_techniques(method, model, X, y):\n",
    "    if model is None:\n",
    "        print('Fehler: Kein trainiertes Modell übergeben!')\n",
    "        return\n",
    "    \n",
    "    print(f'Validierungsmethode: {method}')\n",
    "    \n",
    "    if method == '1':  # K-Fold Cross Validation\n",
    "        print('\\nK-fold Cross-Validation: Die Daten werden in '\n",
    "              'k gleich große Teile (Folds) aufgeteilt. Ein Fold wird als Testdatensatz verwendet, '\n",
    "              'während die restlichen k-1 Folds als Trainingsdatensatz genutzt werden. Der Prozess wird '\n",
    "              'k-mal wiederholt, wobei jedes Mal ein anderer Fold als Testdatensatz dient. Am Ende werden '\n",
    "              'die Ergebnisse gemittelt, um die Gesamtleistung zu berechnen.')\n",
    "        kfold = KFold(n_splits=10, shuffle=True, random_state=1)\n",
    "        results = cross_val_score(model, X, y, cv=kfold)\n",
    "\n",
    "    elif method == '2':  # Stratified K-Fold Cross Validation\n",
    "        print('\\nStratified K-fold Cross-Validation: Funktioniert ähnlich wie K-fold, stellt jedoch sicher, '\n",
    "              'dass in jedem Fold die Klassenverteilung gleich bleibt wie im gesamten Datensatz. '\n",
    "              'Dies ist besonders hilfreich bei unausgewogenen Datensätzen, um aussagekräftigere Ergebnisse zu erhalten.')\n",
    "        skfold = StratifiedKFold(n_splits=10, shuffle=True, random_state=1)\n",
    "        results = cross_val_score(model, X, y, cv=skfold)\n",
    "\n",
    "    elif method == '3':  # Leave-One-Out Cross Validation\n",
    "        print('\\nLOOCV (Leave-One-Out Cross-Validation): Eine Extremform von K-fold, bei der '\n",
    "              'k = n (die Anzahl der Datenpunkte). Jeder einzelne Datenpunkt wird einmal als Testdatensatz verwendet, '\n",
    "              'während die übrigen n-1 Datenpunkte als Trainingsdatensatz dienen. '\n",
    "              'Dies ist rechenintensiv, liefert aber oft präzisere Ergebnisse.')\n",
    "        loo = LeaveOneOut()\n",
    "        results = cross_val_score(model, X, y, cv=loo)\n",
    "\n",
    "    elif method == '4':  # Leave-P-Out Cross Validation\n",
    "        print('\\nLPOCV (Leave-P-Out Cross-Validation): Eine Verallgemeinerung von LOOCV. Statt einen Punkt zu entfernen, werden '\n",
    "              'p Punkte als Testdatensatz genutzt und die restlichen n-p Punkte als Trainingsdatensatz. '\n",
    "              'Die Methode ist flexibel, aber aufgrund der hohen Anzahl möglicher Kombinationen oft rechenaufwendig.')\n",
    "        lpo = LeavePOut(p=5)\n",
    "        results = cross_val_score(model, X, y, cv=lpo)\n",
    "    elif method == '5':  # Repeated Random Test-Train Splits\n",
    "        print('\\nRRTTS (Repeated Random Train-Test Split): Ähnlich wie ein einfacher Train-Test-Split, '\n",
    "              'bei dem der Datensatz in Trainings- und Testdatensatz aufgeteilt wird. '\n",
    "              'Dieser Vorgang wird jedoch mehrmals mit unterschiedlichen Zufallsaufteilungen wiederholt, '\n",
    "              'und die Ergebnisse werden gemittelt. Dies reduziert die Varianz, die durch eine einzige Aufteilung entstehen könnte.')\n",
    "        ssplit = ShuffleSplit(n_splits=20, test_size=0.20, random_state=1)\n",
    "        results = cross_val_score(model, X, y, cv=ssplit)\n",
    "\n",
    "    else:\n",
    "        print('Bitte eine gültige Methode wählen.')\n",
    "        return\n",
    "    \n",
    "    print('\\nErgebnisse der Validation:')\n",
    "    print(results)\n",
    "    print('\\nDurchschnittliche Genauigkeit:', np.mean(results))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "e5cb82f5-6e56-4af8-b25e-cee5e5dc0537",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Funktion für Validierungstechniken\n",
    "def validierung_technik_prozess(trained_model, X, y):\n",
    "    val_techniques = input('\\nAls Validierungstechnik wurde die Methode Train-Test-Split durchgeführt. Möchten Sie eine andere Validierungstechnik verwenden? (Ja/Nein): ')\n",
    "    if val_techniques.lower() == 'ja':\n",
    "        print('Wählen Sie eine Methode (1-5):')\n",
    "        print('1: K-fold')\n",
    "        print('2: Stratified K-fold')\n",
    "        print('3: LOOCV')\n",
    "        print('4: LPOCV')\n",
    "        print('5: RRTTS')\n",
    "\n",
    "        val_techniques_wahl = input()\n",
    "        valid_choices = ['1', '2', '3', '4', '5']\n",
    "        while val_techniques_wahl not in valid_choices:\n",
    "            print('\\nWählen Sie bitte eine Methode von der Liste aus.')\n",
    "            val_techniques_wahl = input()\n",
    "\n",
    "        print('Das kann etwas länger dauern...')\n",
    "        validation_techniques(val_techniques_wahl, trained_model, X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "06a78ef9-545f-4be6-8a42-34ad94234988",
   "metadata": {},
   "outputs": [],
   "source": [
    "def modell_auswahl_und_ausfuehrung(model_switch, X_train, y_train, X_test, y_test, model_wahl):\n",
    "    spezial_modelle = {\n",
    "        '7': 'Max Voting',\n",
    "        '8': 'Stacking',\n",
    "        '9': 'Bagging',\n",
    "        '10': 'Boosting'\n",
    "    }\n",
    "\n",
    "    if model_wahl in spezial_modelle:\n",
    "        final_prediction = model_switch[model_wahl](model_switch,X_train, y_train, X_test, y_test)\n",
    "        return final_prediction\n",
    "    else:\n",
    "        print('Das ausgewählte Modell wird verarbeitet und kann etwas länger dauern')\n",
    "        model_function = model_switch[model_wahl]\n",
    "        trained_model = model_function(X_train, y_train, X_test, y_test)\n",
    "        return trained_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "5d44405a-c957-423b-ad4b-351cbc21a365",
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Möchten Sie die Daten anzeigen? (ja/nein):  ja\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Hier ist der Datensatz als DataFrame:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>longitude</th>\n",
       "      <th>latitude</th>\n",
       "      <th>housing_median_age</th>\n",
       "      <th>total_rooms</th>\n",
       "      <th>total_bedrooms</th>\n",
       "      <th>population</th>\n",
       "      <th>households</th>\n",
       "      <th>median_income</th>\n",
       "      <th>median_house_value</th>\n",
       "      <th>ocean_proximity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-122.23</td>\n",
       "      <td>37.88</td>\n",
       "      <td>41</td>\n",
       "      <td>880</td>\n",
       "      <td>129.0</td>\n",
       "      <td>322</td>\n",
       "      <td>126</td>\n",
       "      <td>8.3252</td>\n",
       "      <td>452600</td>\n",
       "      <td>NEAR BAY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-122.22</td>\n",
       "      <td>37.86</td>\n",
       "      <td>21</td>\n",
       "      <td>7099</td>\n",
       "      <td>1106.0</td>\n",
       "      <td>2401</td>\n",
       "      <td>1138</td>\n",
       "      <td>8.3014</td>\n",
       "      <td>358500</td>\n",
       "      <td>NEAR BAY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-122.24</td>\n",
       "      <td>37.85</td>\n",
       "      <td>52</td>\n",
       "      <td>1467</td>\n",
       "      <td>190.0</td>\n",
       "      <td>496</td>\n",
       "      <td>177</td>\n",
       "      <td>7.2574</td>\n",
       "      <td>352100</td>\n",
       "      <td>NEAR BAY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-122.25</td>\n",
       "      <td>37.85</td>\n",
       "      <td>52</td>\n",
       "      <td>1274</td>\n",
       "      <td>235.0</td>\n",
       "      <td>558</td>\n",
       "      <td>219</td>\n",
       "      <td>5.6431</td>\n",
       "      <td>341300</td>\n",
       "      <td>NEAR BAY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-122.25</td>\n",
       "      <td>37.85</td>\n",
       "      <td>52</td>\n",
       "      <td>1627</td>\n",
       "      <td>280.0</td>\n",
       "      <td>565</td>\n",
       "      <td>259</td>\n",
       "      <td>3.8462</td>\n",
       "      <td>342200</td>\n",
       "      <td>NEAR BAY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20635</th>\n",
       "      <td>-121.09</td>\n",
       "      <td>39.48</td>\n",
       "      <td>25</td>\n",
       "      <td>1665</td>\n",
       "      <td>374.0</td>\n",
       "      <td>845</td>\n",
       "      <td>330</td>\n",
       "      <td>1.5603</td>\n",
       "      <td>78100</td>\n",
       "      <td>INLAND</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20636</th>\n",
       "      <td>-121.21</td>\n",
       "      <td>39.49</td>\n",
       "      <td>18</td>\n",
       "      <td>697</td>\n",
       "      <td>150.0</td>\n",
       "      <td>356</td>\n",
       "      <td>114</td>\n",
       "      <td>2.5568</td>\n",
       "      <td>77100</td>\n",
       "      <td>INLAND</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20637</th>\n",
       "      <td>-121.22</td>\n",
       "      <td>39.43</td>\n",
       "      <td>17</td>\n",
       "      <td>2254</td>\n",
       "      <td>485.0</td>\n",
       "      <td>1007</td>\n",
       "      <td>433</td>\n",
       "      <td>1.7000</td>\n",
       "      <td>92300</td>\n",
       "      <td>INLAND</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20638</th>\n",
       "      <td>-121.32</td>\n",
       "      <td>39.43</td>\n",
       "      <td>18</td>\n",
       "      <td>1860</td>\n",
       "      <td>409.0</td>\n",
       "      <td>741</td>\n",
       "      <td>349</td>\n",
       "      <td>1.8672</td>\n",
       "      <td>84700</td>\n",
       "      <td>INLAND</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20639</th>\n",
       "      <td>-121.24</td>\n",
       "      <td>39.37</td>\n",
       "      <td>16</td>\n",
       "      <td>2785</td>\n",
       "      <td>616.0</td>\n",
       "      <td>1387</td>\n",
       "      <td>530</td>\n",
       "      <td>2.3886</td>\n",
       "      <td>89400</td>\n",
       "      <td>INLAND</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>20640 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       longitude  latitude  housing_median_age  total_rooms  total_bedrooms  \\\n",
       "0        -122.23     37.88                  41          880           129.0   \n",
       "1        -122.22     37.86                  21         7099          1106.0   \n",
       "2        -122.24     37.85                  52         1467           190.0   \n",
       "3        -122.25     37.85                  52         1274           235.0   \n",
       "4        -122.25     37.85                  52         1627           280.0   \n",
       "...          ...       ...                 ...          ...             ...   \n",
       "20635    -121.09     39.48                  25         1665           374.0   \n",
       "20636    -121.21     39.49                  18          697           150.0   \n",
       "20637    -121.22     39.43                  17         2254           485.0   \n",
       "20638    -121.32     39.43                  18         1860           409.0   \n",
       "20639    -121.24     39.37                  16         2785           616.0   \n",
       "\n",
       "       population  households  median_income  median_house_value  \\\n",
       "0             322         126         8.3252              452600   \n",
       "1            2401        1138         8.3014              358500   \n",
       "2             496         177         7.2574              352100   \n",
       "3             558         219         5.6431              341300   \n",
       "4             565         259         3.8462              342200   \n",
       "...           ...         ...            ...                 ...   \n",
       "20635         845         330         1.5603               78100   \n",
       "20636         356         114         2.5568               77100   \n",
       "20637        1007         433         1.7000               92300   \n",
       "20638         741         349         1.8672               84700   \n",
       "20639        1387         530         2.3886               89400   \n",
       "\n",
       "      ocean_proximity  \n",
       "0            NEAR BAY  \n",
       "1            NEAR BAY  \n",
       "2            NEAR BAY  \n",
       "3            NEAR BAY  \n",
       "4            NEAR BAY  \n",
       "...               ...  \n",
       "20635          INLAND  \n",
       "20636          INLAND  \n",
       "20637          INLAND  \n",
       "20638          INLAND  \n",
       "20639          INLAND  \n",
       "\n",
       "[20640 rows x 10 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Möchten Sie mit der Analyse fortfahren? (ja/nein):  ja\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "1. Allgemeine Informationen zum Datensatz:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 20640 entries, 0 to 20639\n",
      "Data columns (total 10 columns):\n",
      " #   Column              Non-Null Count  Dtype  \n",
      "---  ------              --------------  -----  \n",
      " 0   longitude           20640 non-null  float64\n",
      " 1   latitude            20640 non-null  float64\n",
      " 2   housing_median_age  20640 non-null  int64  \n",
      " 3   total_rooms         20640 non-null  int64  \n",
      " 4   total_bedrooms      20433 non-null  float64\n",
      " 5   population          20640 non-null  int64  \n",
      " 6   households          20640 non-null  int64  \n",
      " 7   median_income       20640 non-null  float64\n",
      " 8   median_house_value  20640 non-null  int64  \n",
      " 9   ocean_proximity     20640 non-null  object \n",
      "dtypes: float64(4), int64(5), object(1)\n",
      "memory usage: 1.6+ MB\n",
      "None\n",
      "\n",
      "2. Überprüfung auf fehlende Werte:\n",
      "longitude               0\n",
      "latitude                0\n",
      "housing_median_age      0\n",
      "total_rooms             0\n",
      "total_bedrooms        207\n",
      "population              0\n",
      "households              0\n",
      "median_income           0\n",
      "median_house_value      0\n",
      "ocean_proximity         0\n",
      "dtype: int64\n",
      "\n",
      "3. Überprüfung des Duplikates:\n",
      "Es gibt keine doppelten Zeilen.\n",
      "\n",
      "Fehlende Werte sind vorhanden und können durch die folgenden Methoden vervollständigt werden. \n",
      "\n",
      "Wähle eine Methode zur Imputation fehlender Werte:\n",
      "1: Mean/Median/Mode Imputation (numerische Spalten)\n",
      "2: Predictive Imputation (KNN, numerische Spalten)\n",
      "3: Last Observation Carried Forward (LOCF, alle Spalten)\n",
      "4: Mode Imputation (nicht-numerische Spalten)\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Gib die Nummer der gewünschten Methode ein:  3\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Datensatz nach Last Observation Carried Forward (LOCF):\n",
      "       longitude  latitude  housing_median_age  total_rooms  total_bedrooms  \\\n",
      "0        -122.23     37.88                  41          880           129.0   \n",
      "1        -122.22     37.86                  21         7099          1106.0   \n",
      "2        -122.24     37.85                  52         1467           190.0   \n",
      "3        -122.25     37.85                  52         1274           235.0   \n",
      "4        -122.25     37.85                  52         1627           280.0   \n",
      "...          ...       ...                 ...          ...             ...   \n",
      "20635    -121.09     39.48                  25         1665           374.0   \n",
      "20636    -121.21     39.49                  18          697           150.0   \n",
      "20637    -121.22     39.43                  17         2254           485.0   \n",
      "20638    -121.32     39.43                  18         1860           409.0   \n",
      "20639    -121.24     39.37                  16         2785           616.0   \n",
      "\n",
      "       population  households  median_income  median_house_value  \\\n",
      "0             322         126         8.3252              452600   \n",
      "1            2401        1138         8.3014              358500   \n",
      "2             496         177         7.2574              352100   \n",
      "3             558         219         5.6431              341300   \n",
      "4             565         259         3.8462              342200   \n",
      "...           ...         ...            ...                 ...   \n",
      "20635         845         330         1.5603               78100   \n",
      "20636         356         114         2.5568               77100   \n",
      "20637        1007         433         1.7000               92300   \n",
      "20638         741         349         1.8672               84700   \n",
      "20639        1387         530         2.3886               89400   \n",
      "\n",
      "      ocean_proximity  \n",
      "0            NEAR BAY  \n",
      "1            NEAR BAY  \n",
      "2            NEAR BAY  \n",
      "3            NEAR BAY  \n",
      "4            NEAR BAY  \n",
      "...               ...  \n",
      "20635          INLAND  \n",
      "20636          INLAND  \n",
      "20637          INLAND  \n",
      "20638          INLAND  \n",
      "20639          INLAND  \n",
      "\n",
      "[20640 rows x 10 columns]\n",
      "longitude             0\n",
      "latitude              0\n",
      "housing_median_age    0\n",
      "total_rooms           0\n",
      "total_bedrooms        0\n",
      "population            0\n",
      "households            0\n",
      "median_income         0\n",
      "median_house_value    0\n",
      "ocean_proximity       0\n",
      "dtype: int64\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Möchten Sie eine weitere Methode anwenden? (ja/nein):  nen\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Wähle eine Methode zur Imputation fehlender Werte:\n",
      "1: Mean/Median/Mode Imputation (numerische Spalten)\n",
      "2: Predictive Imputation (KNN, numerische Spalten)\n",
      "3: Last Observation Carried Forward (LOCF, alle Spalten)\n",
      "4: Mode Imputation (nicht-numerische Spalten)\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Gib die Nummer der gewünschten Methode ein:  3\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Datensatz nach Last Observation Carried Forward (LOCF):\n",
      "       longitude  latitude  housing_median_age  total_rooms  total_bedrooms  \\\n",
      "0        -122.23     37.88                  41          880           129.0   \n",
      "1        -122.22     37.86                  21         7099          1106.0   \n",
      "2        -122.24     37.85                  52         1467           190.0   \n",
      "3        -122.25     37.85                  52         1274           235.0   \n",
      "4        -122.25     37.85                  52         1627           280.0   \n",
      "...          ...       ...                 ...          ...             ...   \n",
      "20635    -121.09     39.48                  25         1665           374.0   \n",
      "20636    -121.21     39.49                  18          697           150.0   \n",
      "20637    -121.22     39.43                  17         2254           485.0   \n",
      "20638    -121.32     39.43                  18         1860           409.0   \n",
      "20639    -121.24     39.37                  16         2785           616.0   \n",
      "\n",
      "       population  households  median_income  median_house_value  \\\n",
      "0             322         126         8.3252              452600   \n",
      "1            2401        1138         8.3014              358500   \n",
      "2             496         177         7.2574              352100   \n",
      "3             558         219         5.6431              341300   \n",
      "4             565         259         3.8462              342200   \n",
      "...           ...         ...            ...                 ...   \n",
      "20635         845         330         1.5603               78100   \n",
      "20636         356         114         2.5568               77100   \n",
      "20637        1007         433         1.7000               92300   \n",
      "20638         741         349         1.8672               84700   \n",
      "20639        1387         530         2.3886               89400   \n",
      "\n",
      "      ocean_proximity  \n",
      "0            NEAR BAY  \n",
      "1            NEAR BAY  \n",
      "2            NEAR BAY  \n",
      "3            NEAR BAY  \n",
      "4            NEAR BAY  \n",
      "...               ...  \n",
      "20635          INLAND  \n",
      "20636          INLAND  \n",
      "20637          INLAND  \n",
      "20638          INLAND  \n",
      "20639          INLAND  \n",
      "\n",
      "[20640 rows x 10 columns]\n",
      "longitude             0\n",
      "latitude              0\n",
      "housing_median_age    0\n",
      "total_rooms           0\n",
      "total_bedrooms        0\n",
      "population            0\n",
      "households            0\n",
      "median_income         0\n",
      "median_house_value    0\n",
      "ocean_proximity       0\n",
      "dtype: int64\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Möchten Sie eine weitere Methode anwenden? (ja/nein):  nein\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Imputationsprozess abgeschlossen.\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Möchten Sie Spalten entfernen? (ja/nein):  nein\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Es werden keine weiteren Spalten entfernt.\n",
      "Imputation abgeschlossen.\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "Interrupted by user",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[42], line 5\u001b[0m\n\u001b[0;32m      2\u001b[0m data \u001b[38;5;241m=\u001b[39m laden()\n\u001b[0;32m      4\u001b[0m \u001b[38;5;66;03m# Splitten der Daten in X (Inputs) und y (Output)\u001b[39;00m\n\u001b[1;32m----> 5\u001b[0m [X,y] \u001b[38;5;241m=\u001b[39m split_data(data)\n\u001b[0;32m      7\u001b[0m \u001b[38;5;66;03m# Datenüberprüfung\u001b[39;00m\n\u001b[0;32m      8\u001b[0m X, y \u001b[38;5;241m=\u001b[39m check_data_for_errors(X, y)  \n",
      "Cell \u001b[1;32mIn[10], line 4\u001b[0m, in \u001b[0;36msplit_data\u001b[1;34m(data)\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21msplit_data\u001b[39m(data):\n\u001b[0;32m      3\u001b[0m     \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[1;32m----> 4\u001b[0m         output_cols \u001b[38;5;241m=\u001b[39m \u001b[38;5;28minput\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mGeben Sie die Namen der Output-Spalten (y) ein: \u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m      6\u001b[0m         \u001b[38;5;66;03m# Überprüfen, ob alle eingegebenen Output-Spalten im DataFrame existieren\u001b[39;00m\n\u001b[0;32m      8\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m output_cols \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m data\u001b[38;5;241m.\u001b[39mcolumns:\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\ipykernel\\kernelbase.py:1262\u001b[0m, in \u001b[0;36mKernel.raw_input\u001b[1;34m(self, prompt)\u001b[0m\n\u001b[0;32m   1260\u001b[0m     msg \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mraw_input was called, but this frontend does not support input requests.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1261\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m StdinNotImplementedError(msg)\n\u001b[1;32m-> 1262\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_input_request(\n\u001b[0;32m   1263\u001b[0m     \u001b[38;5;28mstr\u001b[39m(prompt),\n\u001b[0;32m   1264\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_parent_ident[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mshell\u001b[39m\u001b[38;5;124m\"\u001b[39m],\n\u001b[0;32m   1265\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_parent(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mshell\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[0;32m   1266\u001b[0m     password\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[0;32m   1267\u001b[0m )\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\ipykernel\\kernelbase.py:1305\u001b[0m, in \u001b[0;36mKernel._input_request\u001b[1;34m(self, prompt, ident, parent, password)\u001b[0m\n\u001b[0;32m   1302\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyboardInterrupt\u001b[39;00m:\n\u001b[0;32m   1303\u001b[0m     \u001b[38;5;66;03m# re-raise KeyboardInterrupt, to truncate traceback\u001b[39;00m\n\u001b[0;32m   1304\u001b[0m     msg \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInterrupted by user\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m-> 1305\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyboardInterrupt\u001b[39;00m(msg) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1306\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m:\n\u001b[0;32m   1307\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlog\u001b[38;5;241m.\u001b[39mwarning(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInvalid Message:\u001b[39m\u001b[38;5;124m\"\u001b[39m, exc_info\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: Interrupted by user"
     ]
    }
   ],
   "source": [
    "# Laden der Daten\n",
    "data = laden()\n",
    "\n",
    "# Splitten der Daten in X (Inputs) und y (Output)\n",
    "[X,y] = split_data(data)\n",
    "\n",
    "# Datenüberprüfung\n",
    "X, y = check_data_for_errors(X, y)  \n",
    "\n",
    "# Datenaufteilung\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=100)\n",
    "\n",
    "# Feature-Scaling\n",
    "X_train, X_test = feature_scaling(X_train, X_test)\n",
    "\n",
    "# Modellauswahl\n",
    "model_switch = {\n",
    "    '1': model_logistic_regression,\n",
    "    '2': model_svm,\n",
    "    '3': model_knn,\n",
    "    '4': model_gaussian_nb,\n",
    "    '5': model_decision_tree,\n",
    "    '6': model_Random_forest,\n",
    "    '7': model_Max_Voting,\n",
    "    '8': model_Stacking,\n",
    "    '9': model_Bagging,\n",
    "    '10': model_Boosting\n",
    "}\n",
    "\n",
    "model_wahl = input('Soll das ML-Modell automatisch oder manuell ausgewählt werden?: ')\n",
    "\n",
    "if model_wahl.lower() == 'automatisch':\n",
    "    Evaluation = model_TPOTClassifier(X_train, y_train)\n",
    "else:\n",
    "    model_options = [\n",
    "        '1: Logistic Regression',\n",
    "        '2: Support Vector Machines',\n",
    "        '3: K-Nearest Neighbors',\n",
    "        '4: Naive Bayes',\n",
    "        '5: Decision Trees',\n",
    "        '6: Random Forest',\n",
    "        '7: Max Voting',\n",
    "        '8: Model Stacking',\n",
    "        '9: Model Bagging',\n",
    "        '10: Model Boosting'\n",
    "    ]\n",
    "\n",
    "    valid_choices = [str(i) for i in range(1, 11)]\n",
    "    noch_ein_modell = 'ja'\n",
    "\n",
    "    while noch_ein_modell == 'ja':\n",
    "        print('\\nWählen Sie ein Modell (1-10):')\n",
    "        for option in model_options:\n",
    "            print(option)\n",
    "\n",
    "        model_wahl = input()\n",
    "        while model_wahl not in valid_choices:\n",
    "            print('Wählen Sie bitte eine Nummer von der Liste (1-10):')\n",
    "            model_wahl = input()\n",
    "\n",
    "        print(f'Sie haben Modell {model_wahl} gewählt.')\n",
    "        \n",
    "        trained_model = modell_auswahl_und_ausfuehrung(model_switch, X_train, y_train, X_test, y_test, model_wahl)\n",
    "        \n",
    "# Bild zeigen\n",
    "        image_paths = {\n",
    "            '10': 'Boosting_image.png',\n",
    "            '9' : 'Bagging_image.png',\n",
    "            '8' : 'stacking_image.png',\n",
    "            '7' : 'max_voting_image.png'\n",
    "                    }\n",
    "\n",
    "        if model_wahl in image_paths:\n",
    "            img = plt.imread(image_paths[model_wahl])\n",
    "            plt.imshow(img)\n",
    "            plt.axis('off')\n",
    "            plt.show()\n",
    "\n",
    "# Validierungsprozess\n",
    "        if model_wahl not in ['7', '8', '9', '10']:\n",
    "            validierung_technik_prozess(trained_model, X, y)\n",
    "\n",
    "# fragen nach neues Modell\n",
    "        print('\\nMöchten Sie ein anderes Modell ausprobieren? (Ja/Nein): ')\n",
    "        noch_ein_modell = input().strip().lower()\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d63e057e-680b-4398-91d0-6139b94ae079",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f23e35c1-083c-4612-98c2-3d87b779ee13",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
